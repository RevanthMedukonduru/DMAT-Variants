/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
num particles: 1
train dataset size: 50000
test dataset size: 10000
Images Shape:  torch.Size([32, 3, 32, 32]) Latents Shape:  torch.Size([32, 8, 512]) Labels Shape:  torch.Size([32])
  0%|                                                                     | 0/1563 [00:00<?, ?it/s]
lod: 0
Channels: [512, 512, 512, 512, 512, 256, 128, 64] len:  8
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 0
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 2
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 4
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 6
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 8
lod: 0
Channels: [512, 512, 512, 512, 512, 256, 128, 64] len:  8
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 0
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 2
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 4
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 6
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 8
lod: 0
Channels: [512, 512, 512, 512, 512, 256, 128, 64] len:  8
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 0
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 2
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 4
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 6
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 8
lod: 0
Channels: [512, 512, 512, 512, 512, 256, 128, 64] len:  8
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 0
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 2
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 4
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 6
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 8
lod: 0
Channels: [512, 512, 512, 512, 512, 256, 128, 64] len:  8
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 0
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 2
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 4
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 6
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 8
lod: 0
Channels: [512, 512, 512, 512, 512, 256, 128, 64] len:  8
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 0
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 2
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 4
w tensor shape: torch.Size([32, 8, 512])
Attempting to access layer index: 6
w tensor shape: torch.Size([32, 8, 512])
  0%|                                                                     | 0/1563 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "/home/revanth/DMAT-Variants/prepare_classifiers_adv_dual_mix10_ours.py", line 582, in <module>
    train_overall_loss = train(epoch)
  File "/home/revanth/DMAT-Variants/prepare_classifiers_adv_dual_mix10_ours.py", line 464, in train
    total_loss, img_loss, img_loss_adv, img_loss_ladv = net.get_losses(images, images_adv, images_ladv, labels, criterion)
  File "/home/revanth/DMAT-Variants/prepare_classifiers_adv_dual_mix10_ours.py", line 102, in get_losses
    self.detach_all_lora() # detach all lora models if attached
  File "/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'BayesWrap' object has no attribute 'detach_all_lora'